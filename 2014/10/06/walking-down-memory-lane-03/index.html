<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Walking down memory lane (part III) | Yassin java development blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="If you remember our previous article we used a central memory location to share data between two separate threads each running either in the same process or across separate processes. These processes">
<meta property="og:type" content="article">
<meta property="og:title" content="Walking down memory lane (part III)">
<meta property="og:url" content="http://yassinm.github.io/2014/10/06/walking-down-memory-lane-03/">
<meta property="og:site_name" content="Yassin java development blog">
<meta property="og:description" content="If you remember our previous article we used a central memory location to share data between two separate threads each running either in the same process or across separate processes. These processes">
<meta property="og:image" content="/images/walking-down-memory-lane-03-000.png">
<meta property="og:image" content="/images/walking-down-memory-lane-03-001.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Walking down memory lane (part III)">
<meta name="twitter:description" content="If you remember our previous article we used a central memory location to share data between two separate threads each running either in the same process or across separate processes. These processes">

  
    <link rel="alternative" href="/atom.xml" title="Yassin java development blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">

  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Yassin java development blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="submit" value="&#xF002;" class="search-form-submit"><input type="hidden" name="q" value="site:http://yassinm.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-walking-down-memory-lane-03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/10/06/walking-down-memory-lane-03/" class="article-date">
  <time datetime="2014-10-06T04:00:00.000Z" itemprop="datePublished">Oct 6 2014</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Walking down memory lane (part III)
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>If you remember our previous <a href="/2014/09/25/walking-down-memory-lane-02">article</a> we used a central memory location to share data between two separate threads each running either in the same process or across separate processes. These processes could even be located on separate machine or even be written in two different languages.</p>
<img src="/images/walking-down-memory-lane-03-000.png" width="550">

<p>From the above you can see that we only have one thread writing to the shared data. The other thread is only reading this shared data once it is notified that the data was correctly published by the writer thread. Now the question is how do these threads synchronize access to this shared memory location with minimal contention ?</p>
<h2 id="Lock_free_rings_to_the_rescue">Lock free rings to the rescue</h2>
<p>If we need to access this data concurrently we need to let the two separate threads agree (more like synchronize) access based on a locking mechanism. The trick here is to piggy back on the memory model provided by the processor. The cache coherency on x86 systems provides a happens-before guaranty when the data in a certain memory location is modified. However, if the memory is written using the <a href="http://mechanical-sympathy.blogspot.ca/2011/09/single-writer-principle.html" target="_blank" rel="external">Single Writer Principle</a> that data is not propagated forcibly each time a write occurs to invalidate other caches. This basically means that, If the publishing thread writes to this memory location the other thread(s)/core(s) will see this change <em>at some time in the future</em> (and anything that happened before it) without impeding or affecting the publishing thread. As such, the publishing thread can keep updating that location. For the gory details i will point you to this article on <a href="http://mechanical-sympathy.blogspot.ca/2013/02/cpu-cache-flushing-fallacy.html" target="_blank" rel="external">CPU Cache</a> and this one on <a href="http://mechanical-sympathy.blogspot.ca/2011/07/memory-barriersfences.html" target="_blank" rel="external">memory barriers and fences</a>.</p>
<img src="/images/walking-down-memory-lane-03-001.png" width="550">

<p>As can be seen above the two threads behaviour looks, conceptually, like a reservoir with one thread filling it from the top while the other thread is draining it. The memory is treated as a single contiguous stream of data with each message having a unique incrementally sequential location. The reader thread knows that the messages coming down the pipe have the same size are all numbered in a sequential manner and keeps track of the last message position that was fetched from the pipe (head). On the other hand, the publishing thread also knows the sequence number of the last message written to the pipe (tail). Both sequences are augmented incrementally and independently via lock free based mechanism. The algorithm for inserting new elements in this queue must enforce a limit since we only have a very finite space for storing things. Ergo the notion of a circular ring buffer. The writer thread needs to make sure no new elements are inserted when the circular ring buffer is full. On a similar note, the reader thread also makes sure that if there are no new elements added since the last fetch it can spin lock waiting for new elements to be inserted. This algorithm is said to be lock free but not necessarily wait free. Meaning that we can bail out and go do other things when the queue is full/empty , making thus the algorithm as wait free, or if there is nothing else to do we can do a spin lock until the situation is resolved. Meaning we lose the wait free portion but we are still lock free.</p>
<p>One can easily imagine how this buffer can be seen by multiple reader threads with one single publisher making broadcast or parallel type messaging. It is only a matter of adding more head/tail addresses and managing that accordingly when we are adding/removing items in the queue. Once the messages are read by multiple consumer threads they can all act on the same data in a parallel fashion or each consumer thread can be responsible for only part of the sequences based on a partitioning scheme. One particular partitioning technique championed by the <a href="http://lmax-exchange.github.io/disruptor/" target="_blank" rel="external">Disruptor</a> is to use a modulo for each reader so that for example odd sequence messages are handled by one reader while the others are handled by another reader. But we still get the same benefits in that the actual data will be paged by the kernel and available right away without incurring unnecessary cache misses. Once a block of data is written to memory we could use something like <a href="https://www.ibm.com/developerworks/linux/library/j-zerocopy/" target="_blank" rel="external">transferTo</a> to finally achieve a zero copy like network transfer in Java while the publishing thread continues to write new data on a new location. the fact remains that each particular reader thread is effectively free to do what it pleases with the block of data without waiting or synchronizing with other threads.</p>
<p>Furthermore, as we said before, the consumer thread can be anything that can access this memory locations sequentially. This scheme can be used to not only communicate with lower level c/c++ code (or any code written in any language for that matter) but it can also be used to send data directly to GPUs running on the same machine. Once a sufficient amount of data is written by the thread publishing this block of data it can be copied over using DMA over the graphic processing card for example. The same obviously goes for sending/receiving data over high speed NIC cards or proprietary high speed transports like <a href="http://solacesystems.com/" target="_blank" rel="external">solace</a> or <a href="http://www.solarflare.com/" target="_blank" rel="external">solarflare</a>.</p>
<h2 id="Lets_share_some_data_!">Lets share some data !</h2>
<p>I uploaded the code for this article on <a href="https://github.com/yassinm/tools.mlane" target="_blank" rel="external">github</a>. The application is using shared memory mapped files for the memory location. When i run the publisher and subscriber for a 50Million 8 byte (long) one way message stream (from publisher to subscriber only) on a AWS m3.2xlarge instance i am consistently getting ~140 Million messages per second. The test is repeated for 30times and averaged. On my AMD 4 core laptop i am getting a mere 13M messages per second. This is before we start talking about thread affinity and cpu isolation. If you can run this code on your own hardware give me a shout! </p>
<!-- 

[Part I](/2014/09/21/walking-down-memory-lane-01)
[Part II](/2014/09/25/walking-down-memory-lane-02)
[Part III](/2014/10/06/walking-down-memory-lane-03)


-->
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yassinm.github.io/2014/10/06/walking-down-memory-lane-03/" data-id="akgmdopj4tuc8won" class="article-share-link">Share</a>
      
        <a href="http://yassinm.github.io/2014/10/06/walking-down-memory-lane-03/#disqus_thread" class="article-comment-link">Comments</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/memory/">memory</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2014/09/25/walking-down-memory-lane-02/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Walking down memory lane (part II)</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2014/10/06/walking-down-memory-lane-03/">Walking down memory lane (part III)</a>
          </li>
        
          <li>
            <a href="/2014/09/25/walking-down-memory-lane-02/">Walking down memory lane (part II)</a>
          </li>
        
          <li>
            <a href="/2014/09/21/walking-down-memory-lane-01/">Walking down memory lane (part I)</a>
          </li>
        
          <li>
            <a href="/2013/07/13/first-post/">Starting to blog ... finally</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/memory/">memory</a><span class="tag-list-count">3</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/java/" style="font-size: NaNpx;">java</a><a href="/tags/memory/" style="font-size: NaNpx;">memory</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">October 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/09/">September 2014</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/07/">July 2013</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2014 Ymo<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'yassinm';
  
  var disqus_url = 'http://yassinm.github.io/2014/10/06/walking-down-memory-lane-03/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">

  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<script src="/js/script.js" type="text/javascript"></script>


  </div>
</body>
</html>